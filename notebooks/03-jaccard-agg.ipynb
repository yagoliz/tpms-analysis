{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.family\"] = \"Linux Libertine O\"\n",
    "plt.rcParams[\"font.size\"] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = pd.read_csv('../share/tpms-merged-5.csv')\n",
    "filtered.index = pd.to_datetime(filtered['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv('../data/cars.csv')\n",
    "cars_np = cars[['id1','id2','id3','id4','id5','id6','id7','id8']].to_numpy(dtype=str).flatten()\n",
    "cars_np = cars_np[~(cars_np == 'nan')]\n",
    "cars_np = np.random.permutation(cars_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(\n",
    "    id1: str, id2: str, dataset: pd.DataFrame, agg: str = \"1T\"\n",
    ") -> Tuple[int, int, float]:\n",
    "    \"\"\"\n",
    "    Calculate the Jaccard index for a given pair of IDs\n",
    "\n",
    "    ## Parameters:\n",
    "    id1: First id\n",
    "    id2: Second id\n",
    "    dataset: Dataset with the given IDs\n",
    "    ## Returns\n",
    "    pd.Dataframe with the Jaccard index of the ID with the rest of the indices\n",
    "    \"\"\"\n",
    "\n",
    "    # We convert 'time' to datetime if it's not already\n",
    "    if not isinstance(dataset.index, pd.DatetimeIndex):\n",
    "        dataset[\"time\"] = pd.to_datetime(dataset[\"time\"])\n",
    "        dataset.set_index(\"time\", inplace=True)\n",
    "\n",
    "    # Group by the specified time window\n",
    "    grouped = dataset.groupby([pd.Grouper(freq=agg), \"id\"]).size().unstack(fill_value=0)\n",
    "\n",
    "    # Identify time windows where the target ID appears\n",
    "    try:\n",
    "        t1_window = grouped[id1] > 0\n",
    "    except:  # noqa: E722\n",
    "        # print(\"ID1 not found on dataset\")\n",
    "        return (0,0,0.0)\n",
    "\n",
    "    try:\n",
    "        t2_window = grouped[id2] > 0\n",
    "    except:  # noqa: E722\n",
    "        # print(\"ID2 not found on dataset\")\n",
    "        return (t1_window.sum(),0,0.0)\n",
    "\n",
    "    p_A = t1_window.sum()\n",
    "    p_B = t2_window.sum()\n",
    "\n",
    "    p_AiB = (t1_window & t2_window).sum()\n",
    "\n",
    "    return (p_A, p_B, p_AiB, (p_AiB) / (p_A + p_B - p_AiB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_id_in_window(target_id, target_times, df, window='30S'):\n",
    "    # Create a Timedelta window\n",
    "    timedelta = pd.Timedelta(window)\n",
    "\n",
    "    # For each time the target id appears, look in the time window and count ids\n",
    "    count = 0\n",
    "    for time in target_times:\n",
    "        start_time = time - timedelta\n",
    "        end_time = time + timedelta\n",
    "        \n",
    "        timerange = (df.index > start_time) & (df.index < end_time)\n",
    "        count += df.loc[timerange, target_id].any()\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the specified time window\n",
    "grouped = filtered.groupby([pd.Grouper(freq='1S'), \"id\"]).size().unstack(fill_value=0)\n",
    "grouped = grouped.loc[:,cars_np]\n",
    "t1 = grouped[grouped[cars_np[5]] > 0].index\n",
    "find_id_in_window(cars_np[5],t1,grouped,window='30S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard2(\n",
    "    id1: str, id2: str, dataset: pd.DataFrame, agg: str = \"30S\"\n",
    ") -> Tuple[int, int, float]:\n",
    "    \"\"\"\n",
    "    Calculate the Jaccard index for a given pair of IDs\n",
    "\n",
    "    ## Parameters:\n",
    "    id1: First id\n",
    "    id2: Second id\n",
    "    dataset: Dataset with the given IDs\n",
    "    ## Returns\n",
    "    pd.Dataframe with the Jaccard index of the ID with the rest of the indices\n",
    "    \"\"\"\n",
    "\n",
    "    # Group by the specified time window\n",
    "    grouped = dataset.groupby([pd.Grouper(freq='1S'), \"id\"]).size().unstack(fill_value=0)\n",
    "\n",
    "    # Identify time windows where the target ID appears\n",
    "    try:\n",
    "        t1_window = grouped[id1] > 0\n",
    "        t1 = grouped[t1_window].index\n",
    "    except:  # noqa: E722\n",
    "        # print(\"ID1 not found on dataset\")\n",
    "        return (0,0,0.0)\n",
    "\n",
    "    try:\n",
    "        t2_window = grouped[id2] > 0\n",
    "    except:  # noqa: E722\n",
    "        # print(\"ID2 not found on dataset\")\n",
    "        return (t1_window.sum(),0,0.0)\n",
    "\n",
    "    p_A = t1_window.sum()\n",
    "    p_B = t2_window.sum()\n",
    "    \n",
    "    p_AiB = find_id_in_window(id2,t1,grouped,window=agg)\n",
    "\n",
    "    return (p_A, p_B, p_AiB, (p_AiB) / (p_A + p_B - p_AiB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard2(cars_np[8], cars_np[10], filtered, agg='30S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_analysis = [['5S','5 sec.'],['10S','10 sec.'],['30S','30 sec.'],['1T','1 min.'],['2T','2 min.'],['5T','5 min.']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = 0\n",
    "\n",
    "scores = np.zeros((len(cars_np),len(cars_np)))\n",
    "countm = np.zeros((len(cars_np),len(cars_np)))\n",
    "countn = np.zeros((len(cars_np),len(cars_np)))\n",
    "overlp = np.zeros((len(cars_np),len(cars_np)))\n",
    "for i in range(len(cars_np)):\n",
    "    for j in range(i,len(cars_np)):\n",
    "        jac = jaccard(cars_np[i].upper(), cars_np[j].upper(), filtered, agg=grouping_analysis[selected][0])\n",
    "        countm[i,j] = jac[0]\n",
    "        countn[i,j] = jac[1]\n",
    "        overlp[i,j] = jac[2]\n",
    "        scores[i,j] = jac[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_db = 10*np.log10(scores+1e-6)\n",
    "scores_db[scores_db < -30] = -30\n",
    "\n",
    "i_lower = np.tril_indices(scores_db.shape[0], -1)\n",
    "scores[i_lower] = scores.T[i_lower]\n",
    "scores_db[i_lower] = scores_db.T[i_lower]\n",
    "countm[i_lower] = countm.T[i_lower]\n",
    "countn[i_lower] = countn.T[i_lower]\n",
    "overlp[i_lower] = overlp.T[i_lower]\n",
    "\n",
    "pivot_aux = grouped.copy()\n",
    "\n",
    "corr_threshold = -10.0\n",
    "# Let's get all cars\n",
    "cars_ids = np.array(['','','',''], dtype=str)\n",
    "cars_dic = {}\n",
    "\n",
    "car_num = 0\n",
    "while (corr_threshold > -30.0) and (scores_db.shape[0] > 1):\n",
    "    i = 0\n",
    "    while i < scores_db.shape[0]:\n",
    "        row = scores_db[i,:]\n",
    "        best_ids = row[row > corr_threshold]\n",
    "        if len(best_ids) > 1:\n",
    "            actual_ids = np.argsort(row)[::-1][0:min([4,len(best_ids)])]\n",
    "            id_values = pivot_aux.columns[actual_ids]\n",
    "            intersection = np.in1d(cars_ids, id_values)\n",
    "\n",
    "            if (~intersection).any():\n",
    "                if len(id_values) < 4:\n",
    "                    filler = [''] * (4-len(id_values))\n",
    "                    id_values = np.append(id_values,filler)\n",
    "\n",
    "                if ~(id_values == '').any():\n",
    "                    pivot_aux = pivot_aux.drop(id_values,axis=1)\n",
    "                    scores_db = np.delete(scores_db, actual_ids, axis=0)\n",
    "                    scores_db = np.delete(scores_db, actual_ids, axis=1)\n",
    "                    cars_dic[car_num] = id_values.to_numpy()\n",
    "                    car_num+=1\n",
    "                else:\n",
    "                    cars_ids = np.vstack((cars_ids,id_values))\n",
    "            else:\n",
    "                intersection_opposite = np.in1d(id_values, cars_ids)\n",
    "                if (~intersection_opposite).any():\n",
    "                    missing_ids = id_values[~intersection_opposite.any()].to_numpy()\n",
    "                    remaining = 4-len(id_values)\n",
    "\n",
    "                    data_row = np.argmax(intersection.reshape(-1,4).sum(axis=1))\n",
    "                    cars_ids[data_row,remaining:] = missing_ids[:remaining]\n",
    "\n",
    "                    if ~(cars_ids[data_row,:] == '').any():\n",
    "                        found_car = cars_ids[data_row,:]\n",
    "                        pivot_aux = pivot_aux.drop(id_values,axis=1)\n",
    "                        scores_db = np.delete(scores_db, actual_ids, axis=0)\n",
    "                        scores_db = np.delete(scores_db, actual_ids, axis=1)\n",
    "\n",
    "                        cars_dic[car_num] = cars_ids[data_row,:]\n",
    "                        car_num += 1\n",
    "\n",
    "                        cars_ids = np.delete(cars_ids, data_row, axis=0)\n",
    "                        cars_ids[cars_ids.isin(found_car)] = ''\n",
    "        i += 1\n",
    "    \n",
    "    corr_threshold -= 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_analysis = [['5S','5 sec.'],['10S','10 sec.'],['30S','30 sec.'],['1T','1 min.'],['2T','2 min.'],['5T','5 min.']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = 4\n",
    "\n",
    "scores = np.zeros((len(cars_np),len(cars_np)))\n",
    "countm = np.zeros((len(cars_np),len(cars_np)))\n",
    "countn = np.zeros((len(cars_np),len(cars_np)))\n",
    "overlp = np.zeros((len(cars_np),len(cars_np)))\n",
    "for i in range(len(cars_np)):\n",
    "    for j in range(i,len(cars_np)):\n",
    "        jac = jaccard(cars_np[i].upper(), cars_np[j].upper(), filtered, agg=grouping_analysis[selected][0])\n",
    "        countm[i,j] = jac[0]\n",
    "        countn[i,j] = jac[1]\n",
    "        overlp[i,j] = jac[2]\n",
    "        scores[i,j] = jac[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_db = 10*np.log10(scores+1e-6)\n",
    "scores_db[scores_db < -30] = -30\n",
    "\n",
    "i_lower = np.tril_indices(scores_db.shape[0], -1)\n",
    "scores[i_lower] = scores.T[i_lower]\n",
    "scores_db[i_lower] = scores_db.T[i_lower]\n",
    "countm[i_lower] = countm.T[i_lower]\n",
    "countn[i_lower] = countn.T[i_lower]\n",
    "overlp[i_lower] = overlp.T[i_lower]\n",
    "\n",
    "pivot_aux = grouped.copy()\n",
    "\n",
    "corr_threshold = -20.0\n",
    "# Let's get all cars\n",
    "cars_ids = np.array(['','','',''], dtype=str)\n",
    "cars_dic = {}\n",
    "\n",
    "car_num = 0\n",
    "i = 0\n",
    "while i < scores_db.shape[0]:\n",
    "    row = scores_db[i,:]\n",
    "    best_ids = row[row > corr_threshold]\n",
    "    if len(best_ids) > 1:\n",
    "        actual_ids = np.argsort(row)[::-1][0:min([4,len(best_ids)])]\n",
    "        id_values = pivot_aux.columns[actual_ids]\n",
    "        intersection = np.in1d(cars_ids, id_values)\n",
    "\n",
    "        if (~intersection).any():\n",
    "            if len(id_values) < 4:\n",
    "                filler = [''] * (4-len(id_values))\n",
    "                id_values = np.append(id_values,filler)\n",
    "\n",
    "            if ~(id_values == '').any():\n",
    "                pivot_aux = pivot_aux.drop(id_values,axis=1)\n",
    "                scores_db = np.delete(scores_db, actual_ids, axis=0)\n",
    "                scores_db = np.delete(scores_db, actual_ids, axis=1)\n",
    "                cars_dic[car_num] = id_values.to_numpy()\n",
    "                car_num+=1\n",
    "            else:\n",
    "                cars_ids = np.vstack((cars_ids,id_values))\n",
    "        else:\n",
    "            intersection_opposite = np.in1d(id_values, cars_ids)\n",
    "            if (~intersection_opposite).any():\n",
    "                missing_ids = id_values[~intersection_opposite.any()].to_numpy()\n",
    "                remaining = 4-len(id_values)\n",
    "\n",
    "                data_row = np.argmax(intersection.reshape(-1,4).sum(axis=1))\n",
    "                cars_ids[data_row,remaining:] = missing_ids[:remaining]\n",
    "\n",
    "                if ~(cars_ids[data_row,:] == '').any():\n",
    "                    found_car = cars_ids[data_row,:]\n",
    "                    pivot_aux = pivot_aux.drop(id_values,axis=1)\n",
    "                    scores_db = np.delete(scores_db, actual_ids, axis=0)\n",
    "                    scores_db = np.delete(scores_db, actual_ids, axis=1)\n",
    "\n",
    "                    cars_dic[car_num] = cars_ids[data_row,:]\n",
    "                    car_num += 1\n",
    "\n",
    "                    cars_ids = np.delete(cars_ids, data_row, axis=0)\n",
    "                    cars_ids[cars_ids.isin(found_car)] = ''\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
