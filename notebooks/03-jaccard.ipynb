{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.family\"] = \"Linux Libertine O\"\n",
    "plt.rcParams[\"font.size\"] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = 5\n",
    "if isinstance(files, int):\n",
    "    filtered = pd.read_csv(f'../share/tpms-merged-{files}.csv')\n",
    "else:\n",
    "    filtered = pd.read_csv(f'../share/tpms-{files}.csv')\n",
    "filtered.index = pd.to_datetime(filtered['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv('../data/cars.csv')\n",
    "cars_np = cars[['id1','id2','id3','id4','id5','id6','id7','id8']].to_numpy(dtype=str).flatten()\n",
    "cars_np = cars_np[~(cars_np == 'nan')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(\n",
    "    id1: str, id2: str, dataset: pd.DataFrame, agg: str = \"1T\"\n",
    ") -> Tuple[int, int, float]:\n",
    "    \"\"\"\n",
    "    Calculate the Jaccard index for a given pair of IDs\n",
    "\n",
    "    ## Parameters:\n",
    "    id1: First id\n",
    "    id2: Second id\n",
    "    dataset: Dataset with the given IDs\n",
    "    ## Returns\n",
    "    pd.Dataframe with the Jaccard index of the ID with the rest of the indices\n",
    "    \"\"\"\n",
    "\n",
    "    # We convert 'time' to datetime if it's not already\n",
    "    if not isinstance(dataset.index, pd.DatetimeIndex):\n",
    "        dataset[\"time\"] = pd.to_datetime(dataset[\"time\"])\n",
    "        dataset.set_index(\"time\", inplace=True)\n",
    "\n",
    "    # Group by the specified time window\n",
    "    grouped = dataset.groupby([pd.Grouper(freq=agg), \"id\"]).size().unstack(fill_value=0)\n",
    "\n",
    "    # Identify time windows where the target ID appears\n",
    "    try:\n",
    "        t1_window = grouped[id1] > 0\n",
    "    except:  # noqa: E722\n",
    "        # print(\"ID1 not found on dataset\")\n",
    "        return (0,0,0.0)\n",
    "\n",
    "    try:\n",
    "        t2_window = grouped[id2] > 0\n",
    "    except:  # noqa: E722\n",
    "        # print(\"ID2 not found on dataset\")\n",
    "        return (t1_window.sum(),0,0.0)\n",
    "\n",
    "    p_A = t1_window.sum()\n",
    "    p_B = t2_window.sum()\n",
    "\n",
    "    p_AiB = (t1_window & t2_window).sum()\n",
    "\n",
    "    return (p_A, p_B, p_AiB, (p_AiB) / (p_A + p_B - p_AiB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_id_in_window(target_id, target_times, df, window='30S'):\n",
    "    # Create a Timedelta window\n",
    "    timedelta = pd.Timedelta(window)\n",
    "\n",
    "    # For each time the target id appears, look in the time window and count ids\n",
    "    count = 0\n",
    "    for time in target_times:\n",
    "        start_time = time - timedelta\n",
    "        end_time = time + timedelta\n",
    "        \n",
    "        timerange = (df.index > start_time) & (df.index < end_time)\n",
    "        count += df.loc[timerange, target_id].any()\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the specified time window\n",
    "grouped = filtered.groupby([pd.Grouper(freq='1S'), \"id\"]).size().unstack(fill_value=0)\n",
    "t1 = grouped[grouped[cars_np[1]] > 0].index\n",
    "find_id_in_window(cars_np[0],t1,grouped,window='30S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard2(\n",
    "    id1: str, id2: str, dataset: pd.DataFrame, agg: str = \"30S\"\n",
    ") -> Tuple[int, int, float]:\n",
    "    \"\"\"\n",
    "    Calculate the Jaccard index for a given pair of IDs\n",
    "\n",
    "    ## Parameters:\n",
    "    id1: First id\n",
    "    id2: Second id\n",
    "    dataset: Dataset with the given IDs\n",
    "    ## Returns\n",
    "    pd.Dataframe with the Jaccard index of the ID with the rest of the indices\n",
    "    \"\"\"\n",
    "\n",
    "    # Group by the specified time window\n",
    "    grouped = dataset.groupby([pd.Grouper(freq='1S'), \"id\"]).size().unstack(fill_value=0)\n",
    "\n",
    "    # Identify time windows where the target ID appears\n",
    "    try:\n",
    "        t1_window = grouped[id1] > 0\n",
    "        t1 = grouped[t1_window].index\n",
    "    except:  # noqa: E722\n",
    "        # print(\"ID1 not found on dataset\")\n",
    "        return (0,0,0.0)\n",
    "\n",
    "    try:\n",
    "        t2_window = grouped[id2] > 0\n",
    "    except:  # noqa: E722\n",
    "        # print(\"ID2 not found on dataset\")\n",
    "        return (t1_window.sum(),0,0.0)\n",
    "\n",
    "    p_A = t1_window.sum()\n",
    "    p_B = t2_window.sum()\n",
    "    \n",
    "    p_AiB = find_id_in_window(id2,t1,grouped,window=agg)\n",
    "\n",
    "    return (p_A, p_B, p_AiB, (p_AiB) / (p_A + p_B - p_AiB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard2(cars_np[8], cars_np[10], filtered, agg='30S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_analysis = [['5S','5 sec.'],['10S','10 sec.'],['30S','30 sec.'],['1T','1 min.'],['2T','2 min.']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = 3\n",
    "\n",
    "scores = np.zeros((len(cars_np),len(cars_np)))\n",
    "countm = np.zeros((len(cars_np),len(cars_np)))\n",
    "countn = np.zeros((len(cars_np),len(cars_np)))\n",
    "overlp = np.zeros((len(cars_np),len(cars_np)))\n",
    "for i in range(len(cars_np)):\n",
    "    for j in range(i,len(cars_np)):\n",
    "        jac = jaccard(cars_np[i].upper(), cars_np[j].upper(), filtered, agg=grouping_analysis[selected][0])\n",
    "        countm[i,j] = jac[0]\n",
    "        countn[i,j] = jac[1]\n",
    "        overlp[i,j] = jac[2]\n",
    "        scores[i,j] = jac[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_db = 10*np.log10(scores+1e-6)\n",
    "scores_db[scores_db < -30] = -30\n",
    "\n",
    "i_lower = np.tril_indices(scores_db.shape[0], -1)\n",
    "scores[i_lower] = scores.T[i_lower]\n",
    "scores_db[i_lower] = scores_db.T[i_lower]\n",
    "countm[i_lower] = countm.T[i_lower]\n",
    "countn[i_lower] = countn.T[i_lower]\n",
    "overlp[i_lower] = overlp.T[i_lower]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "im = ax.imshow(scores_db, cmap='inferno')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "# ax.set_title(f'Aggregation: {grouping_analysis[selected][1]}')\n",
    "\n",
    "cbar = f.colorbar(im, ax=ax)\n",
    "cbar.set_label('Log Probability')\n",
    "\n",
    "# plt.savefig(f'../pics/correlation/jaccard/jaccard_{grouping_analysis[selected][0]}_n{files}.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wheel_loc = {0: 'FL', 25: 'FR', 50: 'RR', 75: 'RL'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 3*4 + 0\n",
    "sorted_indices = np.argsort(scores[index,:])\n",
    "jaccs = np.array([\n",
    "    np.flip(scores[index,sorted_indices])[0:5],\n",
    "    np.flip(countm[index,sorted_indices])[0:5],\n",
    "    np.flip(countn[index,sorted_indices])[0:5],\n",
    "    np.flip(overlp[index,sorted_indices])[0:5],\n",
    "    np.flip(sorted_indices)[0:5],\n",
    "])\n",
    "\n",
    "table = pd.DataFrame(jaccs.T, columns=['Jacc', 'M', 'N', 'Overlap', 'CarF'])\n",
    "table['Target'] = f'C{int(index//4+1)}-{wheel_loc[int((index/4 - index//4)*100)]}'\n",
    "table['Other'] = table['CarF'].apply(lambda x: f'C{int(x//4 + 1)}-{wheel_loc[int((x/4-x//4)*100)]}')\n",
    "table[['Target','Other','M','N','Overlap','Jacc']].loc[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.loc[1:,:].to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_analysis = [['5S','5 sec.'],['10S','10 sec.'],['30S','30 sec.'],['1T','1 min.'],['2T','2 min.']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = 0\n",
    "t = []\n",
    "\n",
    "for i in range(100):\n",
    "    start = time.time()\n",
    "    scores = np.zeros((len(cars_np),len(cars_np)))\n",
    "    countm = np.zeros((len(cars_np),len(cars_np)))\n",
    "    countn = np.zeros((len(cars_np),len(cars_np)))\n",
    "    overlp = np.zeros((len(cars_np),len(cars_np)))\n",
    "    for i in range(len(cars_np)):\n",
    "        for j in range(i,len(cars_np)):\n",
    "            jac = jaccard(cars_np[i].upper(), cars_np[j].upper(), filtered, agg=grouping_analysis[selected][0])\n",
    "            countm[i,j] = jac[0]\n",
    "            countn[i,j] = jac[1]\n",
    "            overlp[i,j] = jac[2]\n",
    "            scores[i,j] = jac[3]\n",
    "    ending = time.time()\n",
    "\n",
    "    scores_db = 10*np.log10(scores+1e-6)\n",
    "    scores_db[scores_db < -30] = -30\n",
    "\n",
    "    i_lower = np.tril_indices(scores_db.shape[0], -1)\n",
    "    scores[i_lower] = scores.T[i_lower]\n",
    "    scores_db[i_lower] = scores_db.T[i_lower]\n",
    "    countm[i_lower] = countm.T[i_lower]\n",
    "    countn[i_lower] = countn.T[i_lower]\n",
    "    overlp[i_lower] = overlp.T[i_lower]\n",
    "    t.append(ending - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array(t))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
